{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import skorch\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import json\n",
    "\n",
    "import torchvision\n",
    "from torchvision.transforms import v2\n",
    "from torchvision import tv_tensors\n",
    "from torchvision import models\n",
    "\n",
    "import lightning as L\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets\n",
    "class SegmentationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path_to_dataset_root, samples_df, transforms, device):\n",
    "        '''\n",
    "        path_to_dataset - путь до корневой папки с датасетом\n",
    "        instance_names_list - список имен экземпляров БЕЗ РАСШИРЕНИЯ!\n",
    "        transforms - аугментация изображений\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.path_to_dataset_root = path_to_dataset_root\n",
    "        self.samples_df = samples_df\n",
    "        self.transforms = transforms\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples_df.iloc[idx]\n",
    "\n",
    "        file_name = sample['file_name']\n",
    "\n",
    "        path_to_image = os.path.join(self.path_to_dataset_root, 'images', f'{file_name}.npy')\n",
    "        path_to_labels = os.path.join(self.path_to_dataset_root, 'labels', f'{file_name}.npy')\n",
    "\n",
    "        image = torch.as_tensor(np.load(path_to_image))\n",
    "        image = np.load(path_to_image)\n",
    "        # метки читаем как одноканальное изображение\n",
    "        label = torch.as_tensor(np.load(path_to_labels)).long()\n",
    "        \n",
    "        \n",
    "        image = tv_tensors.Image(image, device=self.device)\n",
    "        label = tv_tensors.Mask(label, device=self.device)\n",
    "\n",
    "        transforms_dict = {'image':image, 'mask':label}\n",
    "        transformed = self.transforms(transforms_dict)\n",
    "        return transformed['image'], transformed['mask']#, image\n",
    "    \n",
    "class SegmentationWrapper(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "    def forward(self, x):\n",
    "        return self.model(x)['out']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[5 0]\n",
      "  [0 0]]\n",
      "\n",
      " [[3 0]\n",
      "  [1 1]]\n",
      "\n",
      " [[1 1]\n",
      "  [0 3]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[5, 0],\n",
       "        [0, 1]],\n",
       "\n",
       "       [[4, 0],\n",
       "        [1, 1]],\n",
       "\n",
       "       [[2, 1],\n",
       "        [0, 3]]], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = [\"cat\", \"cat\", \"cat\", \"bird\", \"bird\"]\n",
    "\n",
    "y_pred = [\"cat\", \"cat\", \"cat\", \"bird\", \"cat\"]\n",
    "\n",
    "mcm = metrics.multilabel_confusion_matrix(y_true, y_pred,\n",
    "                            labels=[\"ant\", \"bird\", \"cat\"])\n",
    "print(mcm)\n",
    "y_true = [\"ant\"]\n",
    "y_pred = [\"ant\"]\n",
    "mcm += metrics.multilabel_confusion_matrix(y_true, y_pred,\n",
    "                            labels=[\"ant\", \"bird\", \"cat\"])\n",
    "mcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11,  1],\n",
       "       [ 1,  5]], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcm.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135/135 [00:01<00:00, 105.11it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2.4646, device='cuda:0', grad_fn=<NllLoss2DBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_dataset_info_csv = r'i:\\LANDCOVER_DATA\\MULTISPECTRAL_SATELLITE_DATA\\DATA_FOR_TRAINIG\\data_info_table.csv'\n",
    "path_to_dataset_root = r'I:\\LANDCOVER_DATA\\MULTISPECTRAL_SATELLITE_DATA\\DATA_FOR_TRAINIG'\n",
    "images_df = pd.read_csv(path_to_dataset_info_csv)\n",
    "train_images_df, test_images_df = train_test_split(images_df, test_size=0.3, random_state=0)\n",
    "\n",
    "class_num = images_df['class_num'].iloc[0]\n",
    "\n",
    "with open('surface_classes.json') as fd:\n",
    "    surface_classes_list = json.load(fd)\n",
    "\n",
    "class_name2idx_dict = {n:i for i, n in enumerate(surface_classes_list)}\n",
    "\n",
    "classes_pixels_distribution_df = images_df[surface_classes_list]\n",
    "classes_pixels_num = classes_pixels_distribution_df.sum()\n",
    "classes_weights = classes_pixels_num / classes_pixels_num.sum()\n",
    "\n",
    "\n",
    "transforms = v2.Compose([v2.ToDtype(torch.float32, scale=True)])\n",
    "channels_num = 13\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "model = models.segmentation.fcn_resnet50(weights=models.segmentation.FCN_ResNet50_Weights.DEFAULT)\n",
    "\n",
    "# заменяем входной слой\n",
    "conv1 = model.backbone.conv1\n",
    "stride = conv1.stride\n",
    "kernel_size = conv1.kernel_size\n",
    "out_channels = conv1.out_channels\n",
    "groups = conv1.groups\n",
    "padding = conv1.padding\n",
    "dilation = conv1.dilation\n",
    "is_bias = model.backbone.conv1.bias is not None\n",
    "\n",
    "weights = conv1.weight\n",
    "new_weight = torch.cat([model.backbone.conv1.weight.mean(dim=1).unsqueeze(1)]*channels_num, dim=1)\n",
    "new_conv1 = nn.Conv2d(\n",
    "    in_channels=conv1.in_channels,\n",
    "    out_channels=conv1.out_channels,\n",
    "    kernel_size=conv1.kernel_size,\n",
    "    stride=conv1.stride,\n",
    "    padding=conv1.padding,\n",
    "    dilation=conv1.dilation,\n",
    "    groups=conv1.groups,\n",
    "    bias=conv1.bias is not None\n",
    ")\n",
    "new_conv1.weight = nn.Parameter(new_weight)\n",
    "if conv1.bias is not None:\n",
    "    new_conv1.bias = model.backbone.conv1.bias\n",
    "model.backbone.conv1 = new_conv1\n",
    "\n",
    "# заменяем выходные слои\n",
    "classifier_conv = model.classifier[-1]\n",
    "new_classifier_conv = nn.Conv2d(\n",
    "    in_channels=classifier_conv.in_channels,\n",
    "    out_channels=class_num,\n",
    "    kernel_size=classifier_conv.kernel_size,\n",
    "    stride=classifier_conv.kernel_size,\n",
    "    padding=classifier_conv.padding,\n",
    "    dilation=classifier_conv.dilation,\n",
    "    groups=classifier_conv.groups,\n",
    "    bias=classifier_conv.bias is not None,\n",
    "    )\n",
    "model.classifier[-1] = new_classifier_conv\n",
    "aux_classifier_conv = model.aux_classifier[-1]\n",
    "new_aux_classifier_conv = nn.Conv2d(\n",
    "    in_channels=aux_classifier_conv.in_channels,\n",
    "    out_channels=class_num,\n",
    "    kernel_size=aux_classifier_conv.kernel_size,\n",
    "    stride=aux_classifier_conv.kernel_size,\n",
    "    padding=aux_classifier_conv.padding,\n",
    "    dilation=aux_classifier_conv.dilation,\n",
    "    groups=aux_classifier_conv.groups,\n",
    "    bias=aux_classifier_conv.bias is not None,\n",
    "    )\n",
    "model.aux_classifier[-1] = new_aux_classifier_conv\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = SegmentationWrapper(model)\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = SegmentationDataset(path_to_dataset_root=path_to_dataset_root, samples_df=train_images_df, transforms=transforms, device=device)\n",
    "test_dataset = SegmentationDataset(path_to_dataset_root=path_to_dataset_root, samples_df=test_images_df, transforms=transforms, device=device)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=4)\n",
    "for data, labels in tqdm(test_loader):\n",
    "    pass\n",
    "out = model(data)\n",
    "criterion(out, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'buildings_territory',\n",
       " 1: 'natural_ground',\n",
       " 2: 'natural_grow',\n",
       " 3: 'natural_wetland',\n",
       " 4: 'natural_wood',\n",
       " 5: 'quasi_natural_ground',\n",
       " 6: 'quasi_natural_grow',\n",
       " 7: 'quasi_natural_wetland',\n",
       " 8: 'quasi_natural_wood',\n",
       " 9: 'transport',\n",
       " 10: 'water',\n",
       " 11: 'UNLABELED'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_name2idx_dict\n",
    "{v:k for k, v in class_name2idx_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 175, 175])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, indices = out.max(dim=1)\n",
    "indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_confusion_matrix_2x2(confusion_matrix):\n",
    "    tp = confusion_matrix[1, 1]\n",
    "    tn = confusion_matrix[0, 0]\n",
    "    fp = confusion_matrix[0, 1]\n",
    "    fn = confusion_matrix[1, 0]\n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def compute_accuracy_from_confusion(multiclass_confusion_matrix):\n",
    "    confusion_sum = multiclass_confusion_matrix.sum(axis=0)\n",
    "    tp, tn, fp, fn = decode_confusion_matrix_2x2(confusion_sum)\n",
    "    accuracy = 0\n",
    "    if tp+tn+fp+fn != 0:\n",
    "        accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "    return accuracy\n",
    "\n",
    "def compute_iou_from_confusion(multiclass_confusion_matrix, idx2class_name_dict=None):\n",
    "    #print(f'conf_shape={multiclass_confusion_matrix.shape}')\n",
    "    mean_iou = 0\n",
    "    # {class_name: iou_val}\n",
    "    iou_dict = {}\n",
    "    actual_classes_num = 0\n",
    "    for idx, class_confusion in enumerate(multiclass_confusion_matrix):\n",
    "        #print(f'class_conf_shape={class_confusion.shape}')\n",
    "        tp, tn, fp, fn = decode_confusion_matrix_2x2(class_confusion)\n",
    "        if class_confusion.sum() != tn:\n",
    "            actual_classes_num += 1\n",
    "        class_iou = 0\n",
    "        if tp+fp+fn != 0:\n",
    "            class_iou = tp/(tp+fp+fn)\n",
    "        mean_iou += class_iou\n",
    "        class_name = f'iou_{idx}'\n",
    "        if idx2class_name_dict is not None:\n",
    "            class_name = f'iou_{idx2class_name_dict[idx]}'\n",
    "        iou_dict[class_name] = class_iou\n",
    "    iou_dict['iou_mean'] = mean_iou/actual_classes_num\n",
    "    return iou_dict\n",
    "\n",
    "def compute_pred_mask(pred):\n",
    "    pred = pred.detach()\n",
    "    _, pred_mask = pred.max(dim=1)\n",
    "    return pred_mask.cpu().numpy()\n",
    "\n",
    "\n",
    "\n",
    "class SegmentationModule(L.LightningModule):\n",
    "    def __init__(self, model, criterion, name2class_idx_dict) -> None:\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.name2class_idx_dict = name2class_idx_dict\n",
    "        self.class_idx2name_dict = {v:k for k, v in name2class_idx_dict.items()}\n",
    "        self.train_confusion_matrix = np.zeros((len(self.name2class_idx_dict), 2, 2), dtype=np.int64)\n",
    "        self.val_confusion_matrix = np.zeros((len(self.name2class_idx_dict), 2, 2), dtype=np.int64)\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters())\n",
    "    def compute_pred_lbels(self, pred):\n",
    "        return pred.max(dim=1)\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        data, true_labels = batch\n",
    "        pred = self.model(data)\n",
    "        loss = self.criterion(pred, true_labels)\n",
    "        \n",
    "        pred_labels = compute_pred_mask(pred)\n",
    "        true_labels = true_labels.detach().cpu().numpy()\n",
    "        batch_confusion_matrix = metrics.multilabel_confusion_matrix(true_labels.reshape(-1), pred_labels.reshape(-1),labels=list(self.class_idx2name_dict.keys()))\n",
    "        #print(f'train_batch_conf_type={batch_confusion_matrix.dtype}')\n",
    "        #print(batch_confusion_matrix)\n",
    "        self.train_confusion_matrix += batch_confusion_matrix.astype(np.int64)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        data, true_labels = batch\n",
    "        pred = self.model(data)\n",
    "        loss = self.criterion(pred, labels)\n",
    "        pred_labels = compute_pred_mask(pred)\n",
    "        true_labels = true_labels.detach().cpu().numpy()\n",
    "        batch_confusion_matrix = metrics.multilabel_confusion_matrix(true_labels.reshape(-1), pred_labels.reshape(-1),labels=list(self.class_idx2name_dict.keys()))\n",
    "        #print(f'pred_labels type={pred_labels.dtype}')\n",
    "        #print(f'true_labels type={true_labels.dtype}')\n",
    "        #print(f'val_batch_conf_type={batch_confusion_matrix.dtype}')\n",
    "        #print(batch_confusion_matrix)\n",
    "        self.val_confusion_matrix += batch_confusion_matrix.astype(np.int64)\n",
    "        self.log('val_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self) -> None:\n",
    "        iou_dict = compute_iou_from_confusion(self.train_confusion_matrix,self.class_idx2name_dict)\n",
    "        for name, value in iou_dict.items():\n",
    "            name = f'train_{name}'\n",
    "            self.log(name, value, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.train_confusion_matrix = np.zeros((len(self.name2class_idx_dict), 2, 2), dtype=np.int64)\n",
    "        return super().on_train_epoch_end()\n",
    "    \n",
    "    def on_validation_epoch_end(self) -> None:\n",
    "        iou_dict = compute_iou_from_confusion(self.val_confusion_matrix,self.class_idx2name_dict)\n",
    "        for name, value in iou_dict.items():\n",
    "            name = f'val_{name}'\n",
    "            self.log(name, value, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.val_confusion_matrix = np.zeros((len(self.name2class_idx_dict), 2, 2), dtype=np.int64)\n",
    "        return super().on_validation_epoch_end()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | model     | SegmentationWrapper | 35.3 M | eval \n",
      "1 | criterion | CrossEntropyLoss    | 0      | train\n",
      "----------------------------------------------------------\n",
      "35.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "35.3 M    Total params\n",
      "141.387   Total estimated model params size (MB)\n",
      "1         Modules in train mode\n",
      "163       Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa981707e212402cb308341785b7f9a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mokhail\\miniconda3\\envs\\aggr_rec\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\mokhail\\miniconda3\\envs\\aggr_rec\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aec53641afca456696a0eb7fb210cba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ce13fb8c58f4eaa9903a5c7178a5a70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0da18bad2cf145f8ba859431b73e28a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8999bd9239d94a528054b9424db2d82a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    }
   ],
   "source": [
    "epoch_num = 3\n",
    "\n",
    "segmentation_module = SegmentationModule(model, nn.CrossEntropyLoss(), class_name2idx_dict)\n",
    "\n",
    "logger = CSVLogger(\n",
    "    save_dir = \"outputs\",\n",
    "    name=\"my_exp_name\", \n",
    "    flush_logs_every_n_steps=1, \n",
    "    )\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    mode=\"min\",\n",
    "    filename=\"MLP-{epoch:02d}\",\n",
    "    dirpath=\"outputs\", \n",
    "    save_top_k=1, monitor=\"val_loss\"\n",
    "    \n",
    "    )\n",
    "\n",
    "trainer = L.Trainer(logger=logger,\n",
    "        max_epochs=epoch_num, \n",
    "        #callbacks=[checkpoint_callback],\n",
    "        accelerator = 'cuda'\n",
    "        )\n",
    "\n",
    "trainer.fit(segmentation_module , train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aggr_rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
